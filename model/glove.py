# 传统的 Skip-gram 模型基于局部上下文窗口预测中心词的上下文词，其目标是最大化给定中心词ωi时，上下文词ωj出现的概率。
# 然而，这种局部采样方式忽略了整个语料库中词之间的全局共现信息。
# 为了更好地学习词向量，GloVe 模型引入了全局共现统计，即利用整个语料库中所有词对的共现频率（即全局统计），
# 对损失函数进行重新定义，从而更高效地学习词向量。
# 带全局语料统计的跳元模型 是一种将 Skip-gram 模型从“局部采样”升级为“全局共现建模”的方法，
# 它通过使用整个语料库中词对的共现频率xij来构造损失函数，
# 使得词向量学习更加稳定、高效，并能更好地捕捉词语间的语义关系。
